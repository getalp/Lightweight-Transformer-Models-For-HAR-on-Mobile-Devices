{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hickle as hkl \n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "import requests \n",
    "np.random.seed(0)\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from scipy import signal\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for loading and downloading the dataset\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "\tdataframe = pd.read_csv(filepath, header=None, sep = ',')\n",
    "\treturn dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, prefix=''):\n",
    "\tloaded = list()\n",
    "\tfor name in filenames:\n",
    "\t\tdata = load_file(prefix + name)\n",
    "\t\tloaded.append(data)\n",
    "\t# stack group so that features are the 3rd dimension\n",
    "\tloaded = np.dstack(loaded)\n",
    "\treturn loaded\n",
    " \n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset(group, prefix='',position=''):\n",
    "\tfilepath = prefix + '/' + group + '/' + position\n",
    "\tfilenames = list()\n",
    "\t# body acceleration\n",
    "\tfilenames += ['Acc_x.txt', 'Acc_y.txt', 'Acc_z.txt']\n",
    "\t# body gyroscope\n",
    "\tfilenames += ['Gyr_x.txt', 'Gyr_y.txt', 'Gyr_z.txt']\n",
    "\t# load input data\n",
    "\tx = np.asarray(load_group(filenames, filepath))\n",
    "\t# load class output\n",
    "\ty =  processLabel(load_file(filepath+'/Label.txt'))\n",
    "\treturn x, y\n",
    "\n",
    "# download function for datasets\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matchLabel(activityFileName):\n",
    "    if \"dws\" in activityFileName:\n",
    "        return 0\n",
    "    elif \"ups\" in activityFileName:\n",
    "        return 1\n",
    "    elif \"sit\" in activityFileName:\n",
    "        return 2\n",
    "    elif \"std\" in activityFileName:\n",
    "        return 3\n",
    "    elif \"wlk\" in activityFileName:\n",
    "        return 4\n",
    "    elif \"jog\" in activityFileName:\n",
    "        return 5\n",
    "    else:\n",
    "        print(\"Not found!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentData(accData,time_step,step):\n",
    "#     print(accData.shape)\n",
    "    step = int(step)\n",
    "    segmentAccData = []\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "        segmentAccData.append(accData[i:i+time_step,:])\n",
    "    return np.asarray(segmentAccData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = [\"A_DeviceMotion_data\"]\n",
    "links = [\"https://github.com/mmalekzadeh/motion-sense/blob/master/data/A_DeviceMotion_data.zip?raw=true\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzipping dataset/download\n",
    "os.makedirs('dataset/download',exist_ok=True)\n",
    "os.makedirs('dataset/extracted',exist_ok=True)\n",
    "\n",
    "for i in range(len(fileName)):\n",
    "    data_directory = os.path.abspath(\"dataset/download/\"+str(fileName[i])+\".zip\")\n",
    "    if not os.path.exists(data_directory):\n",
    "        print(\"downloading \"+str(fileName[i]))            \n",
    "        download_url(links[i],data_directory)\n",
    "        print(\"download done\")\n",
    "        data_directory2 =  os.path.abspath(\"dataset/extracted/\"+str(fileName[i])+\".zip\")\n",
    "        print(\"extracting data...\")\n",
    "        with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.abspath(\"dataset/extracted/\"))\n",
    "        print(\"data extracted\")\n",
    "    else:\n",
    "        print(str(fileName[i]) + \" already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedDirectory = os.path.abspath(\"dataset/extracted/A_DeviceMotion_data\")\n",
    "dirs = np.sort([d for d in os.listdir(extractedDirectory) if os.path.isdir(os.path.join(extractedDirectory, d))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientData = {iniArray: [] for iniArray in range(24)}\n",
    "clientLabel = {iniArray: [] for iniArray in range(24)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activityIndex, activityFileName in enumerate(dirs):\n",
    "    subjectFileNames = sorted(os.listdir(extractedDirectory + \"/\"+activityFileName))\n",
    "    for clientIndex, subFileName in enumerate(subjectFileNames):\n",
    "        loadedData = load_file(extractedDirectory+\"/\"+activityFileName+\"/\"+subFileName)\n",
    "        processedData = segmentData(np.hstack((loadedData[:,10:13],loadedData[:,7:10]))[1:,:],128,64)\n",
    "        clientData[clientIndex].append(processedData.astype(np.float32))\n",
    "        clientLabel[clientIndex].append(np.full(processedData.shape[0], matchLabel(activityFileName), dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedData = []\n",
    "processedLabel = []\n",
    "clientSize = []\n",
    "for clientIndex in range(24):\n",
    "    processedData.append(np.vstack((clientData[clientIndex])))\n",
    "    processedLabel.append(np.hstack((clientLabel[clientIndex])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedUserData = np.vstack((processedData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedAccData = combinedUserData[:,:,:3]\n",
    "combinedGyroData = combinedUserData[:,:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accMean =  np.mean(combinedAccData)\n",
    "accStd =  np.std(combinedAccData)\n",
    "                   \n",
    "gyroMean =  np.mean(combinedGyroData)\n",
    "gyroStd =  np.std(combinedGyroData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedAccData = (combinedAccData - accMean)/accStd\n",
    "combinedGyroData = (combinedGyroData - gyroMean)/gyroStd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedUserData = np.dstack((combinedAccData,combinedGyroData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startIndex = 0\n",
    "endIndex = 0 \n",
    "dataName = 'MotionSense'\n",
    "os.makedirs('datasetStandardized/'+dataName, exist_ok=True)\n",
    "for i in range(len(processedData)):\n",
    "    startIndex = endIndex \n",
    "    endIndex = startIndex +  processedData[i].shape[0]\n",
    "    hkl.dump(combinedUserData[startIndex:endIndex],'datasetStandardized/'+dataName+'/UserData'+str(i)+'.hkl' )\n",
    "    hkl.dump(processedLabel[i],'datasetStandardized/'+dataName+'/UserLabel'+str(i)+'.hkl' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data processing finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
