{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:01:41.492692: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-11 18:01:41.747000: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-11 18:01:44.012759: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-11 18:01:44.012879: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-11 18:01:44.012890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hickle as hkl \n",
    "import requests \n",
    "import urllib.request\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "import resampy\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fomating data to adjust for dataset sensor errors\n",
    "def formatData(data,dim):\n",
    "    remainders = data.shape[0]%dim\n",
    "    max_index = data.shape[0] - remainders\n",
    "    data = data[:max_index,:]\n",
    "    new = np.reshape(data, (-1, 128,3))\n",
    "    return new\n",
    "\n",
    "# segment data into windows\n",
    "def segmentData(accData,time_step,step):\n",
    "#     print(accData.shape)\n",
    "    segmentAccData = list()\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "        segmentAccData.append(accData[i:i+time_step,:])\n",
    "    return np.asarray(segmentAccData)\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=0,usecols=[2,3,4])\n",
    "    return dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, filepath='',trainOrEval=0):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(filepath + name)\n",
    "        data = np.asarray(data)\n",
    "#         print(data.shape)\n",
    "#         data = segmentData(data,128,64)\n",
    "        data = np.asarray(data)\n",
    "        loaded.append(data)\n",
    "    return loaded\n",
    "\n",
    "# check if file exist\n",
    "def isReadableFile(file_path, file_name,flag):\n",
    "    full_path = file_path + \"/\" + file_name\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            return False\n",
    "        elif not os.path.isfile(full_path):\n",
    "            return False\n",
    "        elif not os.access(full_path, os.R_OK):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    except IOError as ex:\n",
    "        print (\"I/O error({0}): {1}\".format(ex.errno, ex.strerror))\n",
    "    except Error as ex:\n",
    "        print (\"Error({0}): {1}\".format(ex.errno, ex.strerror))\n",
    "    return False\n",
    "\n",
    "\n",
    "# stairs down 0 \n",
    "# stairs Up   1\n",
    "# jumping     2\n",
    "# lying       3\n",
    "# standing    4 \n",
    "# sitting     5\n",
    "# running/jogging 6\n",
    "# Walking     7\n",
    "\n",
    "# load a dataset group\n",
    "def load_dataset(group, datasetName='',activity='',orientation='',trainOrEval=0,client = 0):\n",
    "    filepath = 'dataset/'+datasetName +'/'+ group + '/'\n",
    "    filenames = list()\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_'+orientation+'.csv',0)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_'+orientation+'.csv']\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_2_'+orientation+'.csv',1)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_2_'+orientation+'.csv']\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_3_'+orientation+'.csv',1)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_3_'+orientation+'.csv']\n",
    "    X = load_group(filenames, filepath,trainOrEval)\n",
    "    return X\n",
    "\n",
    "# download function for datasets\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definign activities and orientations of REALWORLD dataset\n",
    "activities = ['climbingdown','climbingup','jumping','lying','running','sitting','standing','walking'] \n",
    "# activities = ['standing','sitting','walking','climbingup','climbingdown'] \n",
    "\n",
    "orientations = ['chest','forearm','head','shin','thigh','upperarm','waist']\n",
    "# orientations = ['waist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientationKeyMap = dict() \n",
    "for index,value in enumerate(orientations):\n",
    "    orientationKeyMap[value] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading...\n",
      "dataset already downloaded\n",
      "Data already extracted in /data1/home/getalp/eks/dataset/realworld2016_dataset\n"
     ]
    }
   ],
   "source": [
    "# download and unzipping dataset\n",
    "os.makedirs('dataset',exist_ok=True)\n",
    "print(\"downloading...\")            \n",
    "data_directory = os.path.abspath(\"dataset/realworld2016_dataset.zip\")\n",
    "if not os.path.exists(data_directory):\n",
    "    download_url(\"http://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\",data_directory)\n",
    "    print(\"download done\")\n",
    "else:\n",
    "    print(\"dataset already downloaded\")\n",
    "    \n",
    "data_directory2 = os.path.abspath(\"dataset/realworld2016_dataset\")\n",
    "if not os.path.exists(data_directory2): \n",
    "    print(\"extracting data\")\n",
    "    with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.abspath(data_directory2))\n",
    "    print(\"data extracted in \" + data_directory2)\n",
    "else:\n",
    "    print(\"Data already extracted in \" + data_directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unzipping REALWORLD dataset\n",
    "# for id in range(1,16):\n",
    "#     id = str(id)\n",
    "#     for activity in activities:\n",
    "#         for sensor in [\"acc\",\"gyr\"]:\n",
    "#             dirName = sensor\n",
    "#             if(sensor == \"gyr\"):\n",
    "#                 dirName = \"Gyroscope\"\n",
    "#             with zipfile.ZipFile('dataset/realworld2016_dataset/proband'+id+'/data/'+sensor+'_'+str(activity)+'_csv.zip', 'r') as zip_ref:\n",
    "#                 os.makedirs('dataset/REALWORLD/'+dirName+'/'+id, exist_ok=True)\n",
    "#                 zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "\n",
    "#             for i in range (1,4):\n",
    "#                 if os.path.exists('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip'):\n",
    "#                     with zipfile.ZipFile('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip', 'r') as zip_ref:\n",
    "#                         zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "#                     os.remove('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip') \n",
    "#             if os.path.exists('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip'):\n",
    "#                 with zipfile.ZipFile('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip', 'r') as zip_ref:\n",
    "#                     zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "#                 os.remove('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downSampleLowPass(toDownSampleData,factor):\n",
    "    accX = signal.decimate(toDownSampleData[:,0],factor)\n",
    "    accY = signal.decimate(toDownSampleData[:,1],factor)\n",
    "    accZ = signal.decimate(toDownSampleData[:,2],factor)\n",
    "    return np.dstack((accX,accY,accZ)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Number 1 Activity : climbingup Orientation :chest\n",
      "Disalignment of:90903 found\n",
      "Acc data: 32863\n",
      "Gyro data: 123766\n",
      "Client Number 2 Activity : jumping Orientation :chest\n",
      "Disalignment of:12938 found\n",
      "Acc data: 4756\n",
      "Gyro data: 17694\n",
      "Client Number 2 Activity : lying Orientation :chest\n",
      "Disalignment of:66040 found\n",
      "Acc data: 31050\n",
      "Gyro data: 97090\n",
      "Client Number 2 Activity : running Orientation :chest\n",
      "Disalignment of:18983 found\n",
      "Acc data: 30655\n",
      "Gyro data: 49638\n",
      "Client Number 2 Activity : standing Orientation :chest\n",
      "Disalignment of:52189 found\n",
      "Acc data: 30769\n",
      "Gyro data: 82958\n",
      "Client Number 4 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:27708 found\n",
      "Acc data: 11089\n",
      "Gyro data: 38797\n",
      "Client Number 4 Activity : climbingup Orientation :chest\n",
      "Disalignment of:20402 found\n",
      "Acc data: 11676\n",
      "Gyro data: 32078\n",
      "Client Number 4 Activity : running Orientation :chest\n",
      "Disalignment of:139657 found\n",
      "Acc data: 52180\n",
      "Gyro data: 191837\n",
      "Client Number 6 Activity : climbingup Orientation :chest\n",
      "Disalignment of:70838 found\n",
      "Acc data: 25950\n",
      "Gyro data: 96788\n",
      "Client Number 7 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:19811 found\n",
      "Acc data: 9671\n",
      "Gyro data: 29482\n",
      "Client Number 7 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:20389 found\n",
      "Acc data: 10042\n",
      "Gyro data: 30431\n",
      "Client Number 7 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:18327 found\n",
      "Acc data: 9172\n",
      "Gyro data: 27499\n",
      "Client Number 7 Activity : climbingup Orientation :chest\n",
      "Disalignment of:29877 found\n",
      "Acc data: 11254\n",
      "Gyro data: 41131\n",
      "Client Number 7 Activity : climbingup Orientation :chest\n",
      "Disalignment of:19398 found\n",
      "Acc data: 10490\n",
      "Gyro data: 29888\n",
      "Client Number 7 Activity : climbingup Orientation :chest\n",
      "Disalignment of:11908 found\n",
      "Acc data: 10250\n",
      "Gyro data: 22158\n",
      "Client Number 7 Activity : walking Orientation :chest\n",
      "Disalignment of:82463 found\n",
      "Acc data: 30905\n",
      "Gyro data: 113368\n",
      "Client Number 8 Activity : climbingup Orientation :chest\n",
      "Disalignment of:120501 found\n",
      "Acc data: 57853\n",
      "Gyro data: 178354\n",
      "Client Number 8 Activity : lying Orientation :chest\n",
      "Disalignment of:27685 found\n",
      "Acc data: 31654\n",
      "Gyro data: 59339\n",
      "Client Number 9 Activity : climbingup Orientation :chest\n",
      "Disalignment of:30738 found\n",
      "Acc data: 27298\n",
      "Gyro data: 58036\n",
      "Client Number 10 Activity : standing Orientation :chest\n",
      "Disalignment of:24932 found\n",
      "Acc data: 33068\n",
      "Gyro data: 58000\n",
      "Client Number 11 Activity : sitting Orientation :chest\n",
      "Disalignment of:16193 found\n",
      "Acc data: 31336\n",
      "Gyro data: 47529\n",
      "Client Number 12 Activity : climbingup Orientation :chest\n",
      "Disalignment of:66571 found\n",
      "Acc data: 28018\n",
      "Gyro data: 94589\n",
      "Client Number 14 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:19498 found\n",
      "Acc data: 7332\n",
      "Gyro data: 26830\n",
      "Client Number 14 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:15583 found\n",
      "Acc data: 6838\n",
      "Gyro data: 22421\n",
      "Client Number 14 Activity : climbingdown Orientation :chest\n",
      "Disalignment of:18395 found\n",
      "Acc data: 6893\n",
      "Gyro data: 25288\n",
      "Client Number 14 Activity : climbingup Orientation :chest\n",
      "Disalignment of:10479 found\n",
      "Acc data: 9921\n",
      "Gyro data: 20400\n",
      "Client Number 14 Activity : climbingup Orientation :chest\n",
      "Disalignment of:2690 found\n",
      "Acc data: 9641\n",
      "Gyro data: 12331\n",
      "Client Number 14 Activity : walking Orientation :chest\n",
      "Disalignment of:42822 found\n",
      "Acc data: 33577\n",
      "Gyro data: 76399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/getalp/eks/runenv/lib/python3.7/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Number 8 Activity : climbingup Orientation :forearm\n",
      "Disalignment of:1002 found\n",
      "Acc data: 57528\n",
      "Gyro data: 58530\n",
      "Client Number 1 Activity : sitting Orientation :shin\n",
      "Disalignment of:59309 found\n",
      "Acc data: 32877\n",
      "Gyro data: 92186\n",
      "Client Number 14 Activity : climbingdown Orientation :upperarm\n",
      "Disalignment of:7544 found\n",
      "Acc data: 7331\n",
      "Gyro data: 14875\n",
      "Client Number 1 Activity : lying Orientation :waist\n",
      "Disalignment of:29601 found\n",
      "Acc data: 33237\n",
      "Gyro data: 62838\n",
      "Client Number 1 Activity : sitting Orientation :waist\n",
      "Disalignment of:42063 found\n",
      "Acc data: 32875\n",
      "Gyro data: 74938\n"
     ]
    }
   ],
   "source": [
    "# Reading and processing all data\n",
    "\n",
    "clientsOrientation = []\n",
    "\n",
    "nbAnomalies = 0 \n",
    "clientsAccDataByOrientation = []\n",
    "clientsGyroDataByOrientation = []\n",
    "clientsLabelByOrientation = []\n",
    "for orientation in orientations:\n",
    "    \n",
    "    xAccListClient = list()\n",
    "    xGyrListClient = list()\n",
    "    yListClient = list()\n",
    "    \n",
    "    for k in range(1,16):\n",
    "        xAccList = list()\n",
    "        xGyrList = list()\n",
    "        yList = list()\n",
    "        startingIndex = 0\n",
    "        \n",
    "        clientOrientation = []\n",
    "        \n",
    "        for activity in activities:\n",
    "            tempAcc = load_dataset('acc','REALWORLD',activity,orientation,0,k)\n",
    "            tempGyro = load_dataset('Gyroscope','REALWORLD',activity,orientation,0,k)\n",
    "            orientationLength = 0 \n",
    "            for i in range(0, len(tempAcc)):  \n",
    "                accDataLength = len(tempAcc[i])\n",
    "                gyroDataLength = len(tempGyro[i])\n",
    "                difference = accDataLength - gyroDataLength\n",
    "                differenceAbs = abs(difference)\n",
    "\n",
    "                differenceGyro = gyroDataLength - accDataLength\n",
    "                if(differenceGyro > 1000):\n",
    "                    print(\"Client Number \"+str(k) +\" Activity : \"+str(activity) + \" Orientation :\"+str(orientation))\n",
    "                    print(\"Disalignment of:\" +str(differenceAbs) + \" found\")\n",
    "                    print(\"Acc data: \"+str(accDataLength))\n",
    "                    print(\"Gyro data: \"+str(gyroDataLength))\n",
    "                    tempGyro[i] = resampy.resample(tempGyro[i], gyroDataLength, accDataLength,axis = 0)\n",
    "\n",
    "                tempAcc[i] = segmentData(tempAcc[i],128,64)\n",
    "                tempGyro[i] = segmentData(tempGyro[i],128,64)\n",
    "\n",
    "                accDataLength = len(tempAcc[i])\n",
    "                gyroDataLength = len(tempGyro[i])\n",
    "\n",
    "                difference = accDataLength - gyroDataLength\n",
    "                differenceAbs = abs(difference)\n",
    "                if(differenceAbs < 21):\n",
    "                    toAddShape = 0\n",
    "                    if(difference > 0):\n",
    "                        maxIndex = accDataLength-differenceAbs\n",
    "                        xAccList.append(tempAcc[i][:maxIndex,:])\n",
    "                        xGyrList.append(tempGyro[i])\n",
    "                        toAddShape = tempGyro[i].shape[0]\n",
    "                        yList.append(np.full((toAddShape), activities.index(activity)))   \n",
    "                    else:\n",
    "                        maxIndex = gyroDataLength-differenceAbs\n",
    "                        xAccList.append(tempAcc[i])\n",
    "                        xGyrList.append(tempGyro[i][:maxIndex,:])\n",
    "                        toAddShape = tempAcc[i].shape[0]\n",
    "                        yList.append(np.full((toAddShape), activities.index(activity)))\n",
    "#                     clientOrientation.append(np.full(toAddShape,orientationKeyMap[orientation]))\n",
    "#         clientsOrientation.append(np.hstack((clientOrientation)))\n",
    "        xAccListClient.append(np.vstack((xAccList)))\n",
    "        xGyrListClient.append(np.vstack((xGyrList)))\n",
    "        yListClient.append(np.hstack((yList)))\n",
    "    clientsAccDataByOrientation.append(np.asarray(xAccListClient))\n",
    "    clientsGyroDataByOrientation.append(np.asarray(xGyrListClient))\n",
    "    clientsLabelByOrientation.append(np.asarray(yListClient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion to numpy array\n",
    "clientsAccDataByOrientation = np.asarray(clientsAccDataByOrientation)\n",
    "clientsGyroDataByOrientation = np.asarray(clientsGyroDataByOrientation)\n",
    "clientsLabelByOrientation = np.asarray(clientsLabelByOrientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all partcipants client\n",
    "allAcc = np.vstack((np.ravel(clientsAccDataByOrientation)))\n",
    "allGyro = np.vstack((np.ravel(clientsGyroDataByOrientation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating features\n",
    "meanAcc = np.mean(allAcc)\n",
    "stdAcc = np.std(allAcc)\n",
    "\n",
    "meanGyro = np.mean(allGyro)\n",
    "stdGyro = np.std(allGyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel-wise z-normalization\n",
    "normalizedAcc = (clientsAccDataByOrientation - meanAcc)/stdAcc\n",
    "normalizedGyro = (clientsGyroDataByOrientation - meanGyro)/stdGyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedOrientationData = []\n",
    "for normAcc,normGyro in zip(normalizedAcc,normalizedGyro):\n",
    "    stackedOrientationData.append(np.asarray([np.dstack((normAcc,normGyro)) for normAcc,normGyro in zip(normAcc,normGyro)]))\n",
    "stackedOrientationData = np.asarray(stackedOrientationData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'RealWorld'\n",
    "os.makedirs('datasetStandardized/'+dataName, exist_ok=True)\n",
    "hkl.dump(stackedOrientationData,'datasetStandardized/'+dataName+ '/clientsData.hkl' )\n",
    "hkl.dump(clientsLabelByOrientation,'datasetStandardized/'+dataName+ '/clientsLabel.hkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
