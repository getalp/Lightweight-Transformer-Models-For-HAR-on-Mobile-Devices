{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running on googlecolab \n",
    "# !pip install hickle\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# %cd drive/MyDrive/PerCom2021-FL-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import hickle as hkl \n",
    "import requests \n",
    "import urllib.request\n",
    "from scipy import signal\n",
    "import tensorflow as tf\n",
    "import resampy\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fomating data to adjust for dataset sensor errors\n",
    "def formatData(data,dim):\n",
    "    remainders = data.shape[0]%dim\n",
    "    max_index = data.shape[0] - remainders\n",
    "    data = data[:max_index,:]\n",
    "    new = np.reshape(data, (-1, 128,3))\n",
    "    return new\n",
    "\n",
    "# segment data into windows\n",
    "def segmentData(accData,time_step,step):\n",
    "#     print(accData.shape)\n",
    "    segmentAccData = list()\n",
    "    for i in range(0, accData.shape[0] - time_step,step):\n",
    "        segmentAccData.append(accData[i:i+time_step,:])\n",
    "    return np.asarray(segmentAccData)\n",
    "\n",
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = pd.read_csv(filepath, header=0,usecols=[2,3,4])\n",
    "    return dataframe.values\n",
    " \n",
    "# load a list of files, such as x, y, z data for a given variable\n",
    "def load_group(filenames, filepath='',trainOrEval=0):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(filepath + name)\n",
    "        data = np.asarray(data)\n",
    "#         print(data.shape)\n",
    "#         data = segmentData(data,128,64)\n",
    "        data = np.asarray(data)\n",
    "        loaded.append(data)\n",
    "    return loaded\n",
    "\n",
    "# check if file exist\n",
    "def isReadableFile(file_path, file_name,flag):\n",
    "    full_path = file_path + \"/\" + file_name\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            return False\n",
    "        elif not os.path.isfile(full_path):\n",
    "            return False\n",
    "        elif not os.access(full_path, os.R_OK):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    except IOError as ex:\n",
    "        print (\"I/O error({0}): {1}\".format(ex.errno, ex.strerror))\n",
    "    except Error as ex:\n",
    "        print (\"Error({0}): {1}\".format(ex.errno, ex.strerror))\n",
    "    return False\n",
    "\n",
    "\n",
    "# stairs down 0 \n",
    "# stairs Up   1\n",
    "# jumping     2\n",
    "# lying       3\n",
    "# standing    4 \n",
    "# sitting     5\n",
    "# running/jogging 6\n",
    "# Walking     7\n",
    "\n",
    "# load a dataset group\n",
    "def load_dataset(group, datasetName='',activity='',orientation='',trainOrEval=0,client = 0):\n",
    "    filepath = 'dataset/'+datasetName +'/'+ group + '/'\n",
    "    filenames = list()\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_'+orientation+'.csv',0)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_'+orientation+'.csv']\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_2_'+orientation+'.csv',1)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_2_'+orientation+'.csv']\n",
    "    if(isReadableFile('dataset/'+datasetName +'/'+ group, str(client)+'/'+group+'_'+activity+'_3_'+orientation+'.csv',1)):\n",
    "        filenames += [str(client)+'/'+group+'_'+activity+'_3_'+orientation+'.csv']\n",
    "    X = load_group(filenames, filepath,trainOrEval)\n",
    "    return X\n",
    "\n",
    "# download function for datasets\n",
    "def download_url(url, save_path, chunk_size=128):\n",
    "    r = requests.get(url, stream=True)\n",
    "    with open(save_path, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            fd.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definign activities and orientations of REALWORLD dataset\n",
    "activities = ['climbingdown','climbingup','jumping','lying','running','sitting','standing','walking'] \n",
    "# activities = ['standing','sitting','walking','climbingup','climbingdown'] \n",
    "\n",
    "orientations = ['chest','forearm','head','shin','thigh','upperarm','waist']\n",
    "# orientations = ['waist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientationKeyMap = dict() \n",
    "for index,value in enumerate(orientations):\n",
    "    orientationKeyMap[value] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzipping dataset\n",
    "os.makedirs('dataset',exist_ok=True)\n",
    "print(\"downloading...\")            \n",
    "data_directory = os.path.abspath(\"dataset/realworld2016_dataset.zip\")\n",
    "if not os.path.exists(data_directory):\n",
    "    download_url(\"http://wifo5-14.informatik.uni-mannheim.de/sensor/dataset/realworld2016/realworld2016_dataset.zip\",data_directory)\n",
    "    print(\"download done\")\n",
    "else:\n",
    "    print(\"dataset already downloaded\")\n",
    "    \n",
    "data_directory2 = os.path.abspath(\"dataset/realworld2016_dataset\")\n",
    "if not os.path.exists(data_directory2): \n",
    "    print(\"extracting data\")\n",
    "    with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
    "        zip_ref.extractall(os.path.abspath(data_directory2))\n",
    "    print(\"data extracted in \" + data_directory2)\n",
    "else:\n",
    "    print(\"Data already extracted in \" + data_directory2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unzipping REALWORLD dataset\n",
    "for id in range(1,16):\n",
    "    id = str(id)\n",
    "    for activity in activities:\n",
    "        for sensor in [\"acc\",\"gyr\"]:\n",
    "            dirName = sensor\n",
    "            if(sensor == \"gyr\"):\n",
    "                dirName = \"Gyroscope\"\n",
    "            with zipfile.ZipFile('dataset/realworld2016_dataset/proband'+id+'/data/'+sensor+'_'+str(activity)+'_csv.zip', 'r') as zip_ref:\n",
    "                os.makedirs('dataset/REALWORLD/'+dirName+'/'+id, exist_ok=True)\n",
    "                zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "\n",
    "            for i in range (1,4):\n",
    "                if os.path.exists('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip'):\n",
    "                    with zipfile.ZipFile('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip', 'r') as zip_ref:\n",
    "                        zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "                    os.remove('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_'+str(i)+'_csv.zip') \n",
    "            if os.path.exists('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip'):\n",
    "                with zipfile.ZipFile('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip', 'r') as zip_ref:\n",
    "                    zip_ref.extractall('dataset/REALWORLD/'+dirName+'/'+id)\n",
    "                os.remove('dataset/REALWORLD/'+dirName+'/'+id+'/'+sensor+'_'+str(activity)+'_csv.zip') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downSampleLowPass(toDownSampleData,factor):\n",
    "    accX = signal.decimate(toDownSampleData[:,0],factor)\n",
    "    accY = signal.decimate(toDownSampleData[:,1],factor)\n",
    "    accZ = signal.decimate(toDownSampleData[:,2],factor)\n",
    "    return np.dstack((accX,accY,accZ)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading and processing all data\n",
    "\n",
    "clientsOrientation = []\n",
    "\n",
    "nbAnomalies = 0 \n",
    "clientsAccDataByOrientation = []\n",
    "clientsGyroDataByOrientation = []\n",
    "clientsLabelByOrientation = []\n",
    "for orientation in orientations:\n",
    "    \n",
    "    xAccListClient = list()\n",
    "    xGyrListClient = list()\n",
    "    yListClient = list()\n",
    "    \n",
    "    for k in range(1,16):\n",
    "        xAccList = list()\n",
    "        xGyrList = list()\n",
    "        yList = list()\n",
    "        startingIndex = 0\n",
    "        \n",
    "        clientOrientation = []\n",
    "        \n",
    "        for activity in activities:\n",
    "            tempAcc = load_dataset('acc','REALWORLD',activity,orientation,0,k)\n",
    "            tempGyro = load_dataset('Gyroscope','REALWORLD',activity,orientation,0,k)\n",
    "            orientationLength = 0 \n",
    "            for i in range(0, len(tempAcc)):  \n",
    "                accDataLength = len(tempAcc[i])\n",
    "                gyroDataLength = len(tempGyro[i])\n",
    "                difference = accDataLength - gyroDataLength\n",
    "                differenceAbs = abs(difference)\n",
    "                differenceGyro = gyroDataLength - accDataLength\n",
    "                if(differenceGyro > 1000):\n",
    "                    print(\"Client Number \"+str(k) +\" Activity : \"+str(activity) + \" Orientation :\"+str(orientation))\n",
    "                    print(\"Disalignment of:\" +str(differenceAbs) + \" found\")\n",
    "                    print(\"Acc data: \"+str(accDataLength))\n",
    "                    print(\"Gyro data: \"+str(gyroDataLength))\n",
    "                    tempGyro[i] = resampy.resample(tempGyro[i], gyroDataLength, accDataLength,axis = 0)\n",
    "\n",
    "                tempAcc[i] = segmentData(tempAcc[i],128,64)\n",
    "                tempGyro[i] = segmentData(tempGyro[i],128,64)\n",
    "\n",
    "                accDataLength = len(tempAcc[i])\n",
    "                gyroDataLength = len(tempGyro[i])\n",
    "\n",
    "                difference = accDataLength - gyroDataLength\n",
    "                differenceAbs = abs(difference)\n",
    "                if(differenceAbs < 21):\n",
    "                    toAddShape = 0\n",
    "                    if(difference > 0):\n",
    "                        maxIndex = accDataLength-differenceAbs\n",
    "                        xAccList.append(tempAcc[i][:maxIndex,:])\n",
    "                        xGyrList.append(tempGyro[i])\n",
    "                        toAddShape = tempGyro[i].shape[0]\n",
    "                        yList.append(np.full((toAddShape), activities.index(activity)))   \n",
    "                    else:\n",
    "                        maxIndex = gyroDataLength-differenceAbs\n",
    "                        xAccList.append(tempAcc[i])\n",
    "                        xGyrList.append(tempGyro[i][:maxIndex,:])\n",
    "                        toAddShape = tempAcc[i].shape[0]\n",
    "                        yList.append(np.full((toAddShape), activities.index(activity)))\n",
    "#                     clientOrientation.append(np.full(toAddShape,orientationKeyMap[orientation]))\n",
    "#         clientsOrientation.append(np.hstack((clientOrientation)))\n",
    "        xAccListClient.append(np.vstack((xAccList)))\n",
    "        xGyrListClient.append(np.vstack((xGyrList)))\n",
    "        yListClient.append(np.hstack((yList)))\n",
    "    clientsAccDataByOrientation.append(np.asarray(xAccListClient, dtype=object))\n",
    "    clientsGyroDataByOrientation.append(np.asarray(xGyrListClient, dtype=object))\n",
    "    clientsLabelByOrientation.append(np.asarray(yListClient, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion to numpy array\n",
    "clientsAccDataByOrientation = np.asarray(clientsAccDataByOrientation, dtype=object)\n",
    "clientsGyroDataByOrientation = np.asarray(clientsGyroDataByOrientation, dtype=object)\n",
    "clientsLabelByOrientation = np.asarray(clientsLabelByOrientation, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking all partcipants client\n",
    "allAcc = np.vstack((np.ravel(clientsAccDataByOrientation)))\n",
    "allGyro = np.vstack((np.ravel(clientsGyroDataByOrientation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating features\n",
    "meanAcc = np.mean(allAcc)\n",
    "stdAcc = np.std(allAcc)\n",
    "\n",
    "meanGyro = np.mean(allGyro)\n",
    "stdGyro = np.std(allGyro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel-wise z-normalization\n",
    "normalizedAcc = (clientsAccDataByOrientation - meanAcc)/stdAcc\n",
    "normalizedGyro = (clientsGyroDataByOrientation - meanGyro)/stdGyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedOrientationData = []\n",
    "for normAcc,normGyro in zip(normalizedAcc,normalizedGyro):\n",
    "    stackedOrientationData.append(np.asarray([np.dstack((normAcc,normGyro)) for normAcc,normGyro in zip(normAcc,normGyro)],dtype=object))\n",
    "stackedOrientationData = np.asarray(stackedOrientationData, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataName = 'RealWorld'\n",
    "os.makedirs('datasetStandardized/'+dataName, exist_ok=True)\n",
    "hkl.dump(stackedOrientationData,'datasetStandardized/'+dataName+ '/clientsData.hkl' )\n",
    "hkl.dump(clientsLabelByOrientation,'datasetStandardized/'+dataName+ '/clientsLabel.hkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
